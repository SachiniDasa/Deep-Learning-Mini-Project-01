# -*- coding: utf-8 -*-
"""Code

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11E7pckeWVxCP3eoZC2P7LEPvpguhlDQa
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import random
import os
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D , MaxPooling2D ,Dense ,Flatten
from tensorflow.keras.optimizers import SGD

os.chdir("/content/drive/My Drive/Deep Learning/mini_project_1")
os.getcwd()

from PIL import Image
import numpy as np
import pandas as pd
import os

# Function to convert an image to normalized pixel values
def image_to_normalized_pixels(image_path, target_size=(100, 100)):
    try:
        img = Image.open(image_path)
        # Resize the image to a consistent size
        img = img.resize(target_size)
        # Convert the image to a numpy array of pixel values
        pixels = np.array(img)
        # Normalize the pixel values to be in the range [0, 1]
        normalized_pixels = pixels / 255.0
        return normalized_pixels
    except Exception as e:
        print(f"Error processing image {image_path}: {str(e)}")
        return None

# Function to create CSV file for a given dataset
def create_csv(dataset_path, csv_filename, label_csv_filename, decimal_places=6):
    # Lists to store normalized pixel values and labels
    pixels_list = []
    labels_list = []

    for label in os.listdir(dataset_path):
        label_path = os.path.join(dataset_path, label)
        label_value = 1 if label == 'ra' else 0  # Encoding 'ra' as 1 and 'da' as 0

        for image_file in os.listdir(label_path):
            image_path = os.path.join(label_path, image_file)
            normalized_pixels = image_to_normalized_pixels(image_path)

            # Skip images that couldn't be processed
            if normalized_pixels is not None:
                # Flatten the array
                flattened_pixels = normalized_pixels.flatten()
                pixels_list.append(flattened_pixels)
                labels_list.append(label_value)

    # Add normalized pixel values and labels to the DataFrame
    pixels_array = np.array(pixels_list)
    labels_array = np.array(labels_list)

    # Create DataFrames
    pixels_df = pd.DataFrame(pixels_array)
    labels_df = pd.DataFrame(labels_array, columns=['Label'])

    # Save DataFrames to CSV files
    pixels_df.to_csv(csv_filename, index=False, header=False, sep=',', float_format=f'%.{decimal_places}f')
    labels_df.to_csv(label_csv_filename, index=False, sep=',')

# Example usage:
local_dataset_path = '/content/drive/My Drive/Deep Learning/mini_project_1/'
create_csv(os.path.join(local_dataset_path, 'train'), 'input.csv', 'labels.csv', decimal_places=6)
create_csv(os.path.join(local_dataset_path, 'test'), 'input_test.csv', 'labels_test.csv', decimal_places=6)

import pandas as pd
import os
import numpy as np

# Function to create CSV file for labels
def create_label_csv(dataset_path, label_csv_filename):
    labels_data = {'Label': []}

    for label in os.listdir(dataset_path):
        label_path = os.path.join(dataset_path, label)
        label_value = 1 if label == 'ra' else 0

        for _ in os.listdir(label_path):
            labels_data['Label'].append(label_value)

    df_labels = pd.DataFrame(labels_data)
    df_labels.to_csv(label_csv_filename, index=False, header=False, sep=',')

# Example usage:
local_dataset_path = '/content/drive/My Drive/Deep Learning/mini_project_1/'
create_label_csv(os.path.join(local_dataset_path, 'train'), 'labels.csv')
create_label_csv(os.path.join(local_dataset_path, 'test'), 'labels_test.csv')

# Load data
X_train = np.loadtxt('input.csv', delimiter=',')
Y_train = np.loadtxt('labels.csv')
X_test = np.loadtxt('input_test.csv', delimiter=',')
Y_test = np.loadtxt('labels_test.csv')

# Ensure Y_train and Y_test are 1D arrays
Y_train = np.squeeze(Y_train)
Y_test = np.squeeze(Y_test)

print("Shape of X_train: ", X_train.shape)
print("Shape of Y_train: ", Y_train.shape)
print("Shape of X_test: ", X_test.shape)
print("Shape of Y_test: ", Y_test.shape)

X_train = X_train.reshape(len(X_train), 100, 100, 3)
Y_train = Y_train.reshape(len(Y_train), 1)
X_test = X_test.reshape(len(X_test), 100, 100, 3)
Y_test = Y_test.reshape(len(Y_test), 1)
print("Shape of X_train: ", X_train.shape)
print("Shape of Y_train: ", Y_train.shape)
print("Shape of X_test: ", X_test.shape)
print("Shape of Y_test: ", Y_test.shape)

X_train[1,:]

idx = random.randint(0, len(X_train))
plt.imshow(X_train[idx, :])
plt.show()

model = Sequential()
model.add(Conv2D(32, (3,3), activation = 'relu', input_shape = (100, 100, 3)))
model.add(MaxPooling2D((2,2)))
model.add(Conv2D(32, (3,3), activation = 'relu'))
model.add(MaxPooling2D((2,2)))
model.add(Flatten())
model.add(Dense(64, activation = 'relu'))
model.add(Dense(1, activation = 'sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

model.fit(X_train, Y_train, epochs = 5, batch_size = 64)

model.evaluate(X_test, Y_test)

idx2 = random.randint(0, len(Y_test))
plt.imshow(X_test[idx2, :])
plt.show()
y_pred = model.predict(X_test[idx2, :].reshape(1, 100, 100, 3))
y_pred = y_pred > 0.5
print(y_pred)
if(y_pred == 0):
   pred = 'da'
else:
    pred = 'ra'
print("Our model says it is a :", pred)